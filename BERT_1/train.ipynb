{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Train Dataset\n",
    "train_df = pd.read_csv('..\\indexing\\data\\splitted_data\\\\v2\\\\train.csv')\n",
    "train_df['status'] = train_df['status'].apply(lambda x : str(x).strip())\n",
    "\n",
    "#Load Validation Dataset\n",
    "val_df = pd.read_csv('..\\indexing\\data\\splitted_data\\\\v2\\\\val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instansi</th>\n",
       "      <th>status</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lembaga pembiayaan ekspor indonesia</td>\n",
       "      <td>yes</td>\n",
       "      <td>lembaga pembiayaan ekspor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lembaga pembiayaan ekspor indonesia</td>\n",
       "      <td>yes</td>\n",
       "      <td>lpei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lembaga pembiayaan ekspor indonesia</td>\n",
       "      <td>yes</td>\n",
       "      <td>lembaga ekspor indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lembaga pembiayaan ekspor indonesia</td>\n",
       "      <td>yes</td>\n",
       "      <td>pembiayaan ekspor indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lembaga pembiayaan ekspor indonesia</td>\n",
       "      <td>no</td>\n",
       "      <td>pembiayaan indonesia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              instansi status                    reference\n",
       "0  lembaga pembiayaan ekspor indonesia    yes    lembaga pembiayaan ekspor\n",
       "1  lembaga pembiayaan ekspor indonesia    yes                         lpei\n",
       "2  lembaga pembiayaan ekspor indonesia    yes     lembaga ekspor indonesia\n",
       "3  lembaga pembiayaan ekspor indonesia    yes  pembiayaan ekspor indonesia\n",
       "4  lembaga pembiayaan ekspor indonesia     no         pembiayaan indonesia"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instansi : the name of the institution from the reference table\n",
    "#reference : input from the user which will later be predicted\n",
    "#status : actual label, \"yes\" if equal (True), \"no\" if different (False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Pretrained Model (for more model visit : https://huggingface.co/indobenchmark)\n",
    "list_model = ['indobert-base-p1', 'indobert-base-p2']\n",
    "INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "#Load tokenizer for Indobert\n",
    "tokenizer = BertTokenizer.from_pretrained(f'indobenchmark/{list_model[INDEX]}')\n",
    "\n",
    "#labels mapping\n",
    "labels = {'no':0,\n",
    "          'yes':1,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataset Class to feed into model\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['status']]\n",
    "        self.texts = [tokenizer(df['instansi'][i], df['reference'][i],\n",
    "                               padding='max_length', max_length = 512, truncation=True, \n",
    "                               return_tensors=\"pt\") for i in range(df.index[0],df.index[-1] + 1)]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "    \n",
    "        self.bert = BertModel.from_pretrained('indobenchmark/{}'.format(list_model[INDEX]))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train function\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    #Load train and validation dataloader which will be the input model (tensor)\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    #use GPU if available, if not use cpu \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    #Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    #use GPU if available and send model into GPU\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    #List for tracking train loss, val loss, train acc and val acc per epoch\n",
    "    list_epoch = []\n",
    "    list_train_loss = []\n",
    "    list_val_loss = []\n",
    "    train_progress = pd.DataFrame()\n",
    "    best_acc_val = 0\n",
    "\n",
    "    #training iteration\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            #training\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "                \n",
    "                #label\n",
    "                train_label = train_label.to(device)\n",
    "\n",
    "                #input model (mask and input_id)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                #model predict (train data)\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                #train loss and acc calculation\n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            #validation\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "\n",
    "            #Save best model\n",
    "            val_acc_temp = total_acc_val / len(val_data)\n",
    "            if val_acc_temp > best_acc_val :\n",
    "                torch.save(model, \"Models/Best_Model/{}\".format(list_model[INDEX])) \n",
    "            \n",
    "            #save training progress\n",
    "            best_acc_val = val_acc_temp\n",
    "            list_epoch.append(epoch_num+1)\n",
    "            list_train_loss.append(total_loss_train / len(train_data))\n",
    "            list_val_loss.append(total_loss_val / len(val_data))\n",
    "\n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "\n",
    "    #create training progress dataframe, for reporting\n",
    "    train_progress['epoch'] = list_epoch\n",
    "    train_progress['train_loss'] = list_train_loss\n",
    "    train_progress['val_loss'] = list_val_loss\n",
    "\n",
    "    #save training_progress into csv\n",
    "    train_progress.to_csv('result/training_progress/training_progress_{}.csv'.format(list_model[INDEX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter\n",
    "EPOCHS = 1\n",
    "model = BertClassifier()\n",
    "\n",
    "#learning rate\n",
    "LR = 1e-6\n",
    "\n",
    "#call train function\n",
    "train(model, train_df, val_df, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model with test data \n",
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    #print testing accuracy\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test dataset\n",
    "test_df = pd.read_csv('..\\indexing\\data\\splitted_data\\\\v2\\\\test.csv') \n",
    "\n",
    "#Load best model\n",
    "model = torch.load(\"Models/Best_Model/{}\".format(list_model[INDEX]))  \n",
    "\n",
    "#Evaluate\n",
    "evaluate(model, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('bertClass')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a99878c6a92c314e94d3a4d138a1f6ff6d2e216e8b8d331670d92eb51f59927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
